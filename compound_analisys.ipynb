{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main compound analisis after compound dicovery step\n",
    "\n",
    "Requirements: \n",
    "- Exported compounds database in excel format\n",
    "- Exported Chemspider results database in excel format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chemspi_web_db as chemsearch\n",
    "from chemspi_web_db import ChemspiWebDB\n",
    "from chemspi_local_db import ChemspiLocalDB\n",
    "import compound_analisis_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "folder = \"D:/NAS/TEST/input data/\"\n",
    "compounds_database_file = folder + \"Tissue_pos_neg_CSID_RR.xlsx\"\n",
    "\n",
    "web_api_key = \"9GS3pzBwGsrdu0agqqP7buFcYwaaX2GH\"\n",
    "chemspider_local_db_file = folder + \"Tissue_melanoma_negativo_080520_CS2.xlsx\"\n",
    "\n",
    "export_file = folder + \"Tissue_pos_neg_CSID_RR_cachedv2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init resources and databases\n",
    "compounds_table = pd.read_excel(compounds_database_file)\n",
    "chempider_local_db = ChemspiLocalDB(chemspider_local_db_file)\n",
    "chempider_web_db = chemsearch.ChemspiWebDB(web_api_key)\n",
    "\n",
    "# remove not needed columns\n",
    "#compounds_table.drop(columns=['Checked'], inplace=True)\n",
    "\n",
    "print(\"Sucess reading databases\")\n",
    "display(compounds_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Removing duplicated entries\n",
    "- Sort by Name\n",
    "- Sort by area\n",
    "- Sort by retention time\n",
    "- Select from duplicated names: one with highest area then retention time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "compounds_table = utils.remove_duplicated_entries(compounds_table)\n",
    "print(\"Done\")\n",
    "compounds_table.to_excel(export_file + \"_step1.xlsx\")\n",
    "display(compounds_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Find CSId from chemspi databases\n",
    "- Try local first\n",
    "- Try online otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#compounds_table = pd.read_excel(export_file + \"_step1.xlsx\")\n",
    "\n",
    "csid_values = []\n",
    "iupac_values = []\n",
    "\n",
    "num_rows = compounds_table.shape[0]\n",
    "row_count = 0\n",
    "for row_index, row_data in compounds_table.iterrows() :    \n",
    "    row_count += 1\n",
    "    compound_name = str(row_data.Name).lower()\n",
    "    compound_mass = row_data['Molecular Weight']\n",
    "    print('({:d}/{:d}) searching compound info '.format(row_count, num_rows) + compound_name)\n",
    "    \n",
    "    ids = chempider_local_db.find_compound_ids_by_name_mass(compound_name, compound_mass)    \n",
    "    if len(ids) == 0:\n",
    "        print(\"Not found in local db, searching online\")\n",
    "        ids = chempider_web_db.find_compound_ids_by_name_mass(compound_name, compound_mass)\n",
    "    \n",
    "    csid_values.append(utils.CSID_list_to_string(ids))\n",
    "    \n",
    "compounds_table.insert(0, 'CSID', csid_values)\n",
    "#display(compounds_table)\n",
    "compounds_table.to_excel(export_file + \"_step2.xlsx\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Find IUPAC Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compounds_table = pd.read_excel(export_file + \"_step2.xlsx\")\n",
    "iupac_values = []\n",
    "\n",
    "num_rows = compounds_table.shape[0]\n",
    "row_count = 0\n",
    "for row_index, row_data in compounds_table.iterrows() :    \n",
    "    row_count += 1\n",
    "    compound_name = str(row_data.Name).lower()\n",
    "    compound_csids = row_data['CSID']\n",
    "    print('({:d}/{:d}) searching IUPAC Name '.format(row_count, num_rows) + compound_name)\n",
    "    iupac_value = \"\"\n",
    "    if not pd.isna(compound_csids):\n",
    "        for csid in utils.parse_generated_CSID(compound_csids):\n",
    "            compound = chempider_web_db.find_compound_by_id(csid)    \n",
    "            iupac_value = iupac_value + compound.iupac_name + \";\"\n",
    "        \n",
    "        \n",
    "    iupac_values.append(iupac_value)\n",
    "    \n",
    "compounds_table.insert(0, 'IUPAC Name', iupac_values)\n",
    "#display(compounds_table)\n",
    "compounds_table.to_excel(export_file + \"_step3.xlsx\")\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Find External references from chemspi web search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compounds_table = pd.read_excel(export_file + \"_step3.xlsx\")\n",
    "external_databases = ['Human Metabolome Database', 'KEGG', 'LipidMAPS']\n",
    "external_db_info = dict()\n",
    "for db in external_databases:\n",
    "    external_db_info[db] = []\n",
    "        \n",
    "num_rows = compounds_table.shape[0]\n",
    "row_count = 0\n",
    "for row_index, row_data in compounds_table.iterrows() :\n",
    "    # search for external references from known databases\n",
    "    row_count += 1\n",
    "    print('({:d}/{:d}) Finding external references for '.format(row_count, num_rows) + row_data.Name)\n",
    "    external_databases_result = {}\n",
    "    for db in external_databases:\n",
    "        external_databases_result[db] = []\n",
    "    \n",
    "    for csid in utils.parse_generated_CSID(row_data.CSID):\n",
    "        print(\"CSID: \", csid)\n",
    "        external_refs = chemsearch.http_find_compound_external_sources_ids(csid, external_databases)\n",
    "        display(external_refs)\n",
    "        \n",
    "        #if len(warnings) > 0 :\n",
    "        #    display(warnings)\n",
    "        \n",
    "        for db, values in external_refs.items():\n",
    "            external_databases_result[db].extend(values)\n",
    "    \n",
    "    for db, values in external_databases_result.items():\n",
    "        str_result = \"\"\n",
    "        for v in values :\n",
    "            str_result += str(v) + \";\"\n",
    "        external_db_info[db].append(str_result)\n",
    "        \n",
    "insert_pos = 1\n",
    "for db_name, value in external_db_info.items():\n",
    "    compounds_table.insert(insert_pos, db_name, value)\n",
    "    insert_pos += 1\n",
    "\n",
    "#display(compounds_table)\n",
    "compounds_table.to_excel(export_file + \"_step4.xlsx\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Search not found HMDB metabolites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compounds_table = pd.read_excel(export_file + \"_step4.xlsx\")\n",
    "#display(compounds_table)\n",
    "import hmdb_web_db as hmdb_web\n",
    "num_rows = compounds_table.shape[0]\n",
    "row_count = 0\n",
    "for row_index, row_data in compounds_table.iterrows() :\n",
    "    hmdb_info = row_data['Human Metabolome Database']\n",
    "    print('({:d}/{:d})Missing HMDB id: '.format(row_count, num_rows), row_data.Name)\n",
    "    row_count+=1\n",
    "    if pd.isna(hmdb_info) or len(hmdb_info) == 0:\n",
    "        if not row_data.Name.isnumeric():\n",
    "            print(\"Searching by Name\")\n",
    "            metabolites = hmdb_web.search_metabolites_by_name_mass(row_data.Name, row_data['Molecular Weight'])\n",
    "            compounds_table.loc[row_index, \"Human Metabolome Database\"] = utils.CSID_list_to_string(metabolites)\n",
    "        else:\n",
    "            print(\"Searching by IUPAC Name\")\n",
    "            iupac_names = row_data[\"IUPAC Name\"]\n",
    "            names_list = \"\"\n",
    "            for iupac in iupac_names.split(';'):\n",
    "                metabolites = hmdb_web.search_metabolites_by_name_mass(iupac, row_data['Molecular Weight'])\n",
    "                if len(metabolites) > 0:     \n",
    "                    names_list += utils.CSID_list_to_string(metabolites)\n",
    "            compounds_table.loc[row_index, \"Human Metabolome Database\"] = names_list\n",
    "\n",
    "compounds_table.to_excel(export_file + \"_step5.xlsx\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Search HMDB info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hmdb_web_db as hmdb_web\n",
    "\n",
    "#compounds_table = pd.read_excel(export_file + \"_step5.xlsx\")\n",
    "\n",
    "info_titles = [\"Super Class\", \"Class\", \"Sub Class\"]\n",
    "compounds_columns = [\"Name\", \"IUPAC Name\", \"Human Metabolome Database\"]\n",
    "\n",
    "columns = compounds_columns + info_titles\n",
    "output_data = {title : [] for title in columns}\n",
    "\n",
    "#####\n",
    "num_rows = compounds_table.shape[0]\n",
    "row_count = 0\n",
    "for row_index, row_data in compounds_table.iterrows() :\n",
    "    hmdb_ids = row_data['Human Metabolome Database']\n",
    "    print('({:d}/{:d})Searching HMDB info: '.format(row_count, num_rows), hmdb_ids)\n",
    "    row_count+=1\n",
    "    \n",
    "    #### search hmdb info\n",
    "    hmdb_info = None\n",
    "    if not pd.isna(hmdb_ids) and len(str(hmdb_ids)) > 0:\n",
    "        for hmdb_id in hmdb_ids.split(';'):\n",
    "            hmdb_info = hmdb_web.search_metabolite_info_by_id(hmdb_id, info_titles)\n",
    "            print(hmdb_info)\n",
    "            break\n",
    "    \n",
    "    #### set hmdb data\n",
    "    if hmdb_info != None:        \n",
    "        print(hmdb_info)\n",
    "        for column_name, value in hmdb_info.items():        \n",
    "            output_data[column_name].append(value)\n",
    "    else:\n",
    "        for column_name in info_titles:\n",
    "            output_data[column_name].append(\"\")\n",
    "        \n",
    "    #### set compounds data\n",
    "    for column_name in compounds_columns:\n",
    "        output_data[column_name].append(row_data[column_name])\n",
    "        \n",
    "            \n",
    "result = pd.DataFrame.from_dict(output_data)\n",
    "result.to_excel(export_file + \"_step6.xlsx\")\n",
    "display(result)\n",
    "   \n",
    "\n",
    "#compounds_table.to_excel(export_file + \"_step6.xlsx\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
